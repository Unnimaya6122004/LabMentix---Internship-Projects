{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "35m5QtbWiB9F",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "dauF4eBmngu3",
        "GF8Ens_Soomf",
        "g-ATYxFrGrvw",
        "yLjJCtPM0KBk",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "VFOzZv6IFROw",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "KH5McJBi2d8v",
        "-Kee-DAl2viO",
        "gIfDvo9L0UH2"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - **PhonePe Transaction Insights**\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Exploratory Data Analysis(EDA)\n",
        "##### **Contribution**    - Individual\n",
        "##### **Contributor**     - Unnimaya K\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The rise of digital payment platforms has revolutionized the financial landscape in India. Among them, PhonePe has emerged as one of the most widely adopted payment applications, enabling millions of users to perform seamless digital transactions. With the increasing volume of transactions and user engagement, there's a growing need to analyze this data to derive meaningful insights that can drive business decisions, enhance user experience, and support financial innovation. This project, titled PhonePe Transaction Insights, is an extensive Exploratory Data Analysis (EDA) initiative aimed at uncovering patterns and trends in transaction, user, and insurance data made available through the PhonePe Pulse GitHub repository.\n",
        "\n",
        "The core objective of this project is to extract, process, and visualize large volumes of PhonePe data categorized into aggregated data, map-based data, and top-performing metrics. The dataset comprises state-level and district-level statistics across multiple financial categories such as peer-to-peer payments, merchant transactions, recharge payments, and insurance. Through this project, we aim to understand how different regions interact with digital payments, track performance over time, and highlight behavioral patterns across different transaction categories.\n",
        "\n",
        "The project begins with the data extraction phase, where JSON files from the official PhonePe Pulse GitHub repository are downloaded and parsed. These datasets are then loaded into a structured SQL database, ensuring ease of access, integrity, and scalability. Multiple SQL tables are created for different data groups, including aggregated_user, aggregated_transaction, map_user, map_transaction, and various top_* tables.\n",
        "\n",
        "After building the database, SQL queries are written to analyze various business use cases such as:\n",
        "\n",
        "Customer Segmentation based on transaction frequency and volume,\n",
        "\n",
        "Geographical Trends to identify high and low-performing states and districts,\n",
        "\n",
        "Payment Category Popularity to determine where strategic investment is needed,\n",
        "\n",
        "User Engagement and Retention metrics to enhance platform design,\n",
        "\n",
        "and Insurance Transaction Analysis to inform policy development and marketing strategies.\n",
        "\n",
        "The insights derived from SQL analysis are then brought into Python using libraries such as Pandas, Matplotlib, Plotly, and Seaborn. A wide array of visualizations is created to display transaction trends, top contributing states, category-wise distribution, and district-level engagement. These visualizations not only help interpret the data but also act as powerful storytelling tools to guide business strategy.\n",
        "\n",
        "To present these insights interactively, a Streamlit dashboard is developed. The dashboard allows users to explore state-wise statistics, filter data by year and quarter, visualize top-performing PIN codes, and monitor insurance adoption trends. It supports real-time updates and delivers a user-friendly interface for both technical and non-technical stakeholders.\n",
        "\n",
        "The project concludes with the generation of actionable insights, such as identifying underperforming districts for potential market expansion, detecting seasonal transaction patterns, and recommending areas for promotional campaigns or new feature rollouts. These insights have direct applications in customer retention, fraud prevention, marketing optimization, and product development.\n",
        "\n",
        "In summary, PhonePe Transaction Insights demonstrates the power of combining SQL, Python, and interactive visualization tools to explore financial datasets at scale. It highlights the strategic value of data analytics in digital payments and equips decision-makers with the tools needed to stay ahead in a competitive fintech landscape.\n",
        "\n"
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[GitHub Repository Link. Click here.](https://github.com/Unnimaya6122004/LabMentix---Internship-Projects)"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**With the rapid adoption of digital payment platforms like PhonePe, massive volumes of transactional, user, and insurance-related data are generated every day. However, without systematic analysis, this valuable data remains underutilized. There is a growing need to understand the behavioral patterns of users, evaluate regional performance, identify emerging trends, and gain actionable insights that can drive business decisions.This project aims to analyze and visualize structured data from the PhonePe Pulse GitHub repository to uncover key patterns in digital transactions across India. The focus is on examining payment categories, mapping transaction volumes across states and districts, analyzing insurance activity, and identifying top-performing regions and users. The ultimate goal is to empower decision-makers with meaningful insights that can inform customer segmentation, marketing strategies, fraud detection, user engagement, and product development.**"
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "# Data Handling\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "\n",
        "# SQL Connection\n",
        "import sqlite3\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "\n",
        "\n",
        "# Warnings and Settings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Display Options\n",
        "pd.set_option('display.max_columns', None)\n"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone the dataset from GitHub\n",
        "!git clone https://github.com/PhonePe/pulse.git\n"
      ],
      "metadata": {
        "id": "8Xx6MlXZnxor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# Path to the aggregated transaction data\n",
        "base_path = \"/content/pulse/data/aggregated/transaction/country/india/state/\"\n",
        "\n",
        "# Create a list to store rows\n",
        "agg_trans_data = []\n",
        "\n",
        "# Loop through each state folder\n",
        "for state in os.listdir(base_path):\n",
        "    state_path = os.path.join(base_path, state)\n",
        "\n",
        "    for year in os.listdir(state_path):\n",
        "        year_path = os.path.join(state_path, year)\n",
        "\n",
        "        for file in os.listdir(year_path):\n",
        "            if file.endswith(\".json\"):\n",
        "                file_path = os.path.join(year_path, file)\n",
        "\n",
        "                with open(file_path, 'r') as f:\n",
        "                    data = json.load(f)\n",
        "\n",
        "                    try:\n",
        "                        for entry in data['data']['transactionData']:\n",
        "                            row = {\n",
        "                                'State': state,\n",
        "                                'Year': int(year),\n",
        "                                'Quarter': int(file.strip('.json')),\n",
        "                                'Transaction_Type': entry['name'],\n",
        "                                'Transaction_Count': entry['paymentInstruments'][0]['count'],\n",
        "                                'Transaction_Amount': entry['paymentInstruments'][0]['amount']\n",
        "                            }\n",
        "                            agg_trans_data.append(row)\n",
        "                    except:\n",
        "                        pass  # Skipping any malformed or missing data\n",
        "\n",
        "# Create DataFrame\n",
        "df_aggregated_transaction = pd.DataFrame(agg_trans_data)\n",
        "\n",
        "# Show first 5 rows\n",
        "df_aggregated_transaction.head()\n"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to aggregated user data\n",
        "base_path_user = \"/content/pulse/data/aggregated/user/country/india/state/\"\n",
        "\n",
        "# List to store user data\n",
        "agg_user_data = []\n",
        "\n",
        "# Traverse through folders\n",
        "for state in os.listdir(base_path_user):\n",
        "    state_path = os.path.join(base_path_user, state)\n",
        "\n",
        "    for year in os.listdir(state_path):\n",
        "        year_path = os.path.join(state_path, year)\n",
        "\n",
        "        for file in os.listdir(year_path):\n",
        "            if file.endswith(\".json\"):\n",
        "                file_path = os.path.join(year_path, file)\n",
        "\n",
        "                with open(file_path, 'r') as f:\n",
        "                    data = json.load(f)\n",
        "\n",
        "                    try:\n",
        "                        for entry in data['data']['usersByDevice']:\n",
        "                            row = {\n",
        "                                'State': state,\n",
        "                                'Year': int(year),\n",
        "                                'Quarter': int(file.strip('.json')),\n",
        "                                'Brand': entry['brand'],\n",
        "                                'User_Count': entry['count'],\n",
        "                                'User_Percentage': entry['percentage']\n",
        "                            }\n",
        "                            agg_user_data.append(row)\n",
        "                    except:\n",
        "                        pass  # Skipping if data structure is inconsistent\n",
        "\n",
        "# Create DataFrame\n",
        "df_aggregated_user = pd.DataFrame(agg_user_data)\n",
        "\n",
        "# Show first few rows\n",
        "df_aggregated_user.head()\n"
      ],
      "metadata": {
        "id": "tb6ds2mtoVmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to aggregated insurance data\n",
        "base_path_insurance = \"/content/pulse/data/aggregated/insurance/country/india/state/\"\n",
        "\n",
        "# List to store insurance data\n",
        "agg_insurance_data = []\n",
        "\n",
        "# Traverse through folders\n",
        "for state in os.listdir(base_path_insurance):\n",
        "    state_path = os.path.join(base_path_insurance, state)\n",
        "\n",
        "    for year in os.listdir(state_path):\n",
        "        year_path = os.path.join(state_path, year)\n",
        "\n",
        "        for file in os.listdir(year_path):\n",
        "            if file.endswith(\".json\"):\n",
        "                file_path = os.path.join(year_path, file)\n",
        "\n",
        "                with open(file_path, 'r') as f:\n",
        "                    data = json.load(f)\n",
        "\n",
        "                    try:\n",
        "                        for entry in data['data']['transactionData']:\n",
        "                            row = {\n",
        "                                'State': state,\n",
        "                                'Year': int(year),\n",
        "                                'Quarter': int(file.strip('.json')),\n",
        "                                'Insurance_Type': entry['name'],\n",
        "                                'Insurance_Count': entry['paymentInstruments'][0]['count'],\n",
        "                                'Insurance_Amount': entry['paymentInstruments'][0]['amount']\n",
        "                            }\n",
        "                            agg_insurance_data.append(row)\n",
        "                    except:\n",
        "                        pass  # Skipping malformed or empty entries\n",
        "\n",
        "# Create DataFrame\n",
        "df_aggregated_insurance = pd.DataFrame(agg_insurance_data)\n",
        "\n",
        "# Display the first few rows\n",
        "df_aggregated_insurance.head()\n"
      ],
      "metadata": {
        "id": "r7CCP-G0oYVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to map user data\n",
        "path_map_user = \"/content/pulse/data/map/user/hover/country/india/state/\"\n",
        "\n",
        "map_user_data = []\n",
        "\n",
        "for state in os.listdir(path_map_user):\n",
        "    state_path = os.path.join(path_map_user, state)\n",
        "\n",
        "    for year in os.listdir(state_path):\n",
        "        year_path = os.path.join(state_path, year)\n",
        "\n",
        "        for file in os.listdir(year_path):\n",
        "            if file.endswith(\".json\"):\n",
        "                file_path = os.path.join(year_path, file)\n",
        "                with open(file_path, 'r') as f:\n",
        "                    data = json.load(f)\n",
        "\n",
        "                    try:\n",
        "                        for district, metrics in data['data']['hoverData'].items():\n",
        "                            row = {\n",
        "                                'State': state,\n",
        "                                'Year': int(year),\n",
        "                                'Quarter': int(file.strip(\".json\")),\n",
        "                                'District': district,\n",
        "                                'Registered_Users': metrics.get('registeredUsers', 0),\n",
        "                                'App_Opens': metrics.get('appOpens', 0)\n",
        "                            }\n",
        "                            map_user_data.append(row)\n",
        "                    except:\n",
        "                        pass\n",
        "\n",
        "df_map_user = pd.DataFrame(map_user_data)\n",
        "df_map_user.head()\n"
      ],
      "metadata": {
        "id": "wBfhY7Zuo4TR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to map transaction data\n",
        "base_path_map = \"/content/pulse/data/map/transaction/hover/country/india/state/\"\n",
        "\n",
        "# List to store map transaction data\n",
        "map_trans_data = []\n",
        "\n",
        "# Traverse through folders\n",
        "for state in os.listdir(base_path_map):\n",
        "    state_path = os.path.join(base_path_map, state)\n",
        "\n",
        "    for year in os.listdir(state_path):\n",
        "        year_path = os.path.join(state_path, year)\n",
        "\n",
        "        for file in os.listdir(year_path):\n",
        "            if file.endswith(\".json\"):\n",
        "                file_path = os.path.join(year_path, file)\n",
        "\n",
        "                with open(file_path, 'r') as f:\n",
        "                    data = json.load(f)\n",
        "\n",
        "                    try:\n",
        "                        for district in data['data']['hoverDataList']:\n",
        "                            row = {\n",
        "                                'State': state,\n",
        "                                'Year': int(year),\n",
        "                                'Quarter': int(file.strip('.json')),\n",
        "                                'District': district['name'],\n",
        "                                'Transaction_Count': district['metric'][0]['count'],\n",
        "                                'Transaction_Amount': district['metric'][0]['amount']\n",
        "                            }\n",
        "                            map_trans_data.append(row)\n",
        "                    except:\n",
        "                        pass\n",
        "\n",
        "# Create DataFrame\n",
        "df_map_transaction = pd.DataFrame(map_trans_data)\n",
        "\n",
        "# Display the first few rows\n",
        "df_map_transaction.head()\n"
      ],
      "metadata": {
        "id": "i-EgzmBqpefH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If already loaded, you can just rename\n",
        "df_map_map = df_map_transaction.copy()\n",
        "\n",
        "# Otherwise, reuse the earlier loading block and assign to df_map_map\n"
      ],
      "metadata": {
        "id": "Y7w4TMeDpt4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to map insurance data\n",
        "path_map_insurance = \"/content/pulse/data/map/insurance/hover/country/india/state/\"\n",
        "\n",
        "map_insurance_data = []\n",
        "\n",
        "for state in os.listdir(path_map_insurance):\n",
        "    state_path = os.path.join(path_map_insurance, state)\n",
        "\n",
        "    for year in os.listdir(state_path):\n",
        "        year_path = os.path.join(state_path, year)\n",
        "\n",
        "        for file in os.listdir(year_path):\n",
        "            if file.endswith(\".json\"):\n",
        "                file_path = os.path.join(year_path, file)\n",
        "                with open(file_path, 'r') as f:\n",
        "                    data = json.load(f)\n",
        "\n",
        "                    try:\n",
        "                        for district in data['data']['hoverDataList']:\n",
        "                            row = {\n",
        "                                'State': state,\n",
        "                                'Year': int(year),\n",
        "                                'Quarter': int(file.strip('.json')),\n",
        "                                'District': district['name'],\n",
        "                                'Insurance_Count': district['metric'][0]['count'],\n",
        "                                'Insurance_Amount': district['metric'][0]['amount']\n",
        "                            }\n",
        "                            map_insurance_data.append(row)\n",
        "                    except:\n",
        "                        pass\n",
        "\n",
        "df_map_insurance = pd.DataFrame(map_insurance_data)\n",
        "df_map_insurance.head()\n"
      ],
      "metadata": {
        "id": "eEX7CHuypzho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to top user data\n",
        "path_top_user = \"/content/pulse/data/top/user/country/india/state/\"\n",
        "\n",
        "top_user_data = []\n",
        "\n",
        "for state in os.listdir(path_top_user):\n",
        "    state_path = os.path.join(path_top_user, state)\n",
        "\n",
        "    for year in os.listdir(state_path):\n",
        "        year_path = os.path.join(state_path, year)\n",
        "\n",
        "        for file in os.listdir(year_path):\n",
        "            if file.endswith('.json'):\n",
        "                file_path = os.path.join(year_path, file)\n",
        "\n",
        "                with open(file_path, 'r') as f:\n",
        "                    data = json.load(f)\n",
        "\n",
        "                    try:\n",
        "                        for entry in data['data']['districts']:\n",
        "                            row = {\n",
        "                                'State': state,\n",
        "                                'Year': int(year),\n",
        "                                'Quarter': int(file.strip('.json')),\n",
        "                                'Name': entry['name'],\n",
        "                                'Registered_Users': entry['registeredUsers']\n",
        "                            }\n",
        "                            top_user_data.append(row)\n",
        "                    except:\n",
        "                        pass\n",
        "\n",
        "df_top_user = pd.DataFrame(top_user_data)\n",
        "df_top_user.head()\n"
      ],
      "metadata": {
        "id": "cb8I3sVRp2kX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to top transaction data\n",
        "path_top_map = \"/content/pulse/data/top/transaction/country/india/state/\"\n",
        "\n",
        "top_map_data = []\n",
        "\n",
        "for state in os.listdir(path_top_map):\n",
        "    state_path = os.path.join(path_top_map, state)\n",
        "\n",
        "    for year in os.listdir(state_path):\n",
        "        year_path = os.path.join(state_path, year)\n",
        "\n",
        "        for file in os.listdir(year_path):\n",
        "            if file.endswith('.json'):\n",
        "                file_path = os.path.join(year_path, file)\n",
        "\n",
        "                with open(file_path, 'r') as f:\n",
        "                    data = json.load(f)\n",
        "\n",
        "                    try:\n",
        "                        for entry in data['data']['districts']:\n",
        "                            row = {\n",
        "                                'State': state,\n",
        "                                'Year': int(year),\n",
        "                                'Quarter': int(file.strip('.json')),\n",
        "                                'Entity_Type': 'District',\n",
        "                                'Name': entry['entityName'],\n",
        "                                'Count': entry['metric']['count'],\n",
        "                                'Amount': entry['metric']['amount']\n",
        "                            }\n",
        "                            top_map_data.append(row)\n",
        "\n",
        "                        for entry in data['data']['pincodes']:\n",
        "                            row = {\n",
        "                                'State': state,\n",
        "                                'Year': int(year),\n",
        "                                'Quarter': int(file.strip('.json')),\n",
        "                                'Entity_Type': 'Pincode',\n",
        "                                'Name': entry['entityName'],\n",
        "                                'Count': entry['metric']['count'],\n",
        "                                'Amount': entry['metric']['amount']\n",
        "                            }\n",
        "                            top_map_data.append(row)\n",
        "                    except:\n",
        "                        pass\n",
        "\n",
        "df_top_map = pd.DataFrame(top_map_data)\n",
        "df_top_map.head()\n"
      ],
      "metadata": {
        "id": "yRWT93KIuakd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to top insurance data\n",
        "path_top_insurance = \"/content/pulse/data/top/insurance/country/india/state/\"\n",
        "\n",
        "top_insurance_data = []\n",
        "\n",
        "for state in os.listdir(path_top_insurance):\n",
        "    state_path = os.path.join(path_top_insurance, state)\n",
        "\n",
        "    for year in os.listdir(state_path):\n",
        "        year_path = os.path.join(state_path, year)\n",
        "\n",
        "        for file in os.listdir(year_path):\n",
        "            if file.endswith('.json'):\n",
        "                file_path = os.path.join(year_path, file)\n",
        "\n",
        "                with open(file_path, 'r') as f:\n",
        "                    data = json.load(f)\n",
        "\n",
        "                    try:\n",
        "                        for entry in data['data']['districts']:\n",
        "                            row = {\n",
        "                                'State': state,\n",
        "                                'Year': int(year),\n",
        "                                'Quarter': int(file.strip('.json')),\n",
        "                                'Name': entry['entityName'],\n",
        "                                'Count': entry['metric']['count'],\n",
        "                                'Amount': entry['metric']['amount']\n",
        "                            }\n",
        "                            top_insurance_data.append(row)\n",
        "                    except:\n",
        "                        pass\n",
        "\n",
        "df_top_insurance = pd.DataFrame(top_insurance_data)\n",
        "df_top_insurance.head()\n"
      ],
      "metadata": {
        "id": "wFhpjs-pufe1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "# Check shape and preview of each DataFrame\n",
        "\n",
        "print(\"🔹 Aggregated Transaction Dataset\")\n",
        "print(df_aggregated_transaction.shape)\n",
        "display(df_aggregated_transaction.head())\n",
        "\n",
        "print(\"\\n🔹 Aggregated User Dataset\")\n",
        "print(df_aggregated_user.shape)\n",
        "display(df_aggregated_user.head())\n",
        "\n",
        "print(\"\\n🔹 Aggregated Insurance Dataset\")\n",
        "print(df_aggregated_insurance.shape)\n",
        "display(df_aggregated_insurance.head())\n",
        "\n",
        "print(\"\\n🔹 Map User Dataset\")\n",
        "print(df_map_user.shape)\n",
        "display(df_map_user.head())\n",
        "\n",
        "print(\"\\n🔹 Map Transaction Dataset\")\n",
        "print(df_map_map.shape)\n",
        "display(df_map_map.head())\n",
        "\n",
        "print(\"\\n🔹 Map Insurance Dataset\")\n",
        "print(df_map_insurance.shape)\n",
        "display(df_map_insurance.head())\n",
        "\n",
        "print(\"\\n🔹 Top User Dataset\")\n",
        "print(df_top_user.shape)\n",
        "display(df_top_user.head())\n",
        "\n",
        "print(\"\\n🔹 Top Map Dataset\")\n",
        "print(df_top_map.shape)\n",
        "display(df_top_map.head())\n",
        "\n",
        "print(\"\\n🔹 Top Insurance Dataset\")\n",
        "print(df_top_insurance.shape)\n",
        "display(df_top_insurance.head())\n"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "# Function to print row & column count\n",
        "def print_shape(df, name):\n",
        "    print(f\"{name}: {df.shape[0]} rows × {df.shape[1]} columns\")\n",
        "\n",
        "# Print for all dataframes\n",
        "print(\"📊 Dataset Shape Overview:\\n\")\n",
        "\n",
        "print_shape(df_aggregated_transaction, \"🔹 df_aggregated_transaction\")\n",
        "print_shape(df_aggregated_user, \"🔹 df_aggregated_user\")\n",
        "print_shape(df_aggregated_insurance, \"🔹 df_aggregated_insurance\")\n",
        "\n",
        "print_shape(df_map_user, \"🔹 df_map_user\")\n",
        "print_shape(df_map_map, \"🔹 df_map_map\")\n",
        "print_shape(df_map_insurance, \"🔹 df_map_insurance\")\n",
        "\n",
        "print_shape(df_top_user, \"🔹 df_top_user\")\n",
        "print_shape(df_top_map, \"🔹 df_top_map\")\n",
        "print_shape(df_top_insurance, \"🔹 df_top_insurance\")\n"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "# Function to display dataset info\n",
        "def display_info(df, name):\n",
        "    print(f\"\\n🔍 Dataset Info for: {name}\")\n",
        "    print(\"-\" * 40)\n",
        "    print(df.info())\n",
        "\n",
        "# Run info for all datasets\n",
        "display_info(df_aggregated_transaction, \"df_aggregated_transaction\")\n",
        "display_info(df_aggregated_user, \"df_aggregated_user\")\n",
        "display_info(df_aggregated_insurance, \"df_aggregated_insurance\")\n",
        "\n",
        "display_info(df_map_user, \"df_map_user\")\n",
        "display_info(df_map_map, \"df_map_map\")\n",
        "display_info(df_map_insurance, \"df_map_insurance\")\n",
        "\n",
        "display_info(df_top_user, \"df_top_user\")\n",
        "display_info(df_top_map, \"df_top_map\")\n",
        "display_info(df_top_insurance, \"df_top_insurance\")\n"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "# Function to count duplicate rows\n",
        "def count_duplicates(df, name):\n",
        "    dup_count = df.duplicated().sum()\n",
        "    print(f\"{name} ➤ Duplicate Rows: {dup_count}\")\n",
        "\n",
        "# Check duplicates in all datasets\n",
        "print(\"📌 Duplicate Row Count in Each Dataset:\\n\")\n",
        "\n",
        "count_duplicates(df_aggregated_transaction, \"df_aggregated_transaction\")\n",
        "count_duplicates(df_aggregated_user, \"df_aggregated_user\")\n",
        "count_duplicates(df_aggregated_insurance, \"df_aggregated_insurance\")\n",
        "\n",
        "count_duplicates(df_map_user, \"df_map_user\")\n",
        "count_duplicates(df_map_map, \"df_map_map\")\n",
        "count_duplicates(df_map_insurance, \"df_map_insurance\")\n",
        "\n",
        "count_duplicates(df_top_user, \"df_top_user\")\n",
        "count_duplicates(df_top_map, \"df_top_map\")\n",
        "count_duplicates(df_top_insurance, \"df_top_insurance\")\n"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "# Function to count missing values\n",
        "def count_missing_values(df, name):\n",
        "    print(f\"\\n🔍 Missing Values in {name}\")\n",
        "    print(\"-\" * 40)\n",
        "    print(df.isnull().sum())\n",
        "\n",
        "# Run for all datasets\n",
        "count_missing_values(df_aggregated_transaction, \"df_aggregated_transaction\")\n",
        "count_missing_values(df_aggregated_user, \"df_aggregated_user\")\n",
        "count_missing_values(df_aggregated_insurance, \"df_aggregated_insurance\")\n",
        "\n",
        "count_missing_values(df_map_user, \"df_map_user\")\n",
        "count_missing_values(df_map_map, \"df_map_map\")\n",
        "count_missing_values(df_map_insurance, \"df_map_insurance\")\n",
        "\n",
        "count_missing_values(df_top_user, \"df_top_user\")\n",
        "count_missing_values(df_top_map, \"df_top_map\")\n",
        "count_missing_values(df_top_insurance, \"df_top_insurance\")\n"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "# Visualize missing values in df_aggregated_user\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.heatmap(df_aggregated_user.isnull(), cbar=False, cmap=\"viridis\")\n",
        "plt.title(\"Missing Values Heatmap - Aggregated User\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For df_map_user\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.heatmap(df_map_user.isnull(), cbar=False, cmap=\"magma\")\n",
        "plt.title(\"Missing Values Heatmap - Map User\")\n",
        "plt.show()\n",
        "\n",
        "# For df_top_map\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.heatmap(df_top_map.isnull(), cbar=False, cmap=\"coolwarm\")\n",
        "plt.title(\"Missing Values Heatmap - Top Map\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "25eOGg4VwSHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "\n",
        "# Create in-memory database (or use a file: 'phonepe.db')\n",
        "conn = sqlite3.connect('/content/phonepe.db')  # use 'phonepe.db' for persistent file\n",
        "cursor = conn.cursor()\n"
      ],
      "metadata": {
        "id": "UxhX8Z8FyYDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aggregated Tables\n",
        "df_aggregated_transaction.to_sql('aggregated_transaction', conn, index=False, if_exists='replace')\n",
        "df_aggregated_user.to_sql('aggregated_user', conn, index=False, if_exists='replace')\n",
        "df_aggregated_insurance.to_sql('aggregated_insurance', conn, index=False, if_exists='replace')\n",
        "\n",
        "# Map Tables\n",
        "df_map_user.to_sql('map_user', conn, index=False, if_exists='replace')\n",
        "df_map_map.to_sql('map_map', conn, index=False, if_exists='replace')\n",
        "df_map_insurance.to_sql('map_insurance', conn, index=False, if_exists='replace')\n",
        "\n",
        "# Top Tables\n",
        "df_top_user.to_sql('top_user', conn, index=False, if_exists='replace')\n",
        "df_top_map.to_sql('top_map', conn, index=False, if_exists='replace')\n",
        "df_top_insurance.to_sql('top_insurance', conn, index=False, if_exists='replace')\n"
      ],
      "metadata": {
        "id": "OzQ1XIMKyp4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List all tables in the SQLite DB\n",
        "tables_df = pd.read_sql_query(\"SELECT name FROM sqlite_master WHERE type='table';\", conn)\n",
        "tables_df\n"
      ],
      "metadata": {
        "id": "x0hsExmWy90k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#total no of rows\n",
        "tables = [\n",
        "    'aggregated_transaction', 'aggregated_user', 'aggregated_insurance',\n",
        "    'map_user', 'map_map', 'map_insurance',\n",
        "    'top_user', 'top_map', 'top_insurance'\n",
        "]\n",
        "\n",
        "for table in tables:\n",
        "    query = f\"SELECT COUNT(*) FROM {table};\"\n",
        "    result = cursor.execute(query).fetchone()[0]\n",
        "    print(f\"📦 {table} ➤ Total Rows: {result}\")\n"
      ],
      "metadata": {
        "id": "GJVEmGA_zQGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preview sample rows from one table\n",
        "pd.read_sql_query(\"SELECT * FROM aggregated_transaction LIMIT 5;\", conn)\n"
      ],
      "metadata": {
        "id": "Z4zLWlIszZIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"\"\"\n",
        "SELECT\n",
        "    SUM(CASE WHEN Transaction_Amount IS NULL THEN 1 ELSE 0 END) AS null_transaction_amount,\n",
        "    SUM(CASE WHEN Transaction_Count IS NULL THEN 1 ELSE 0 END) AS null_transaction_count\n",
        "FROM aggregated_transaction;\n",
        "\"\"\"\n",
        "pd.read_sql_query(query, conn)\n"
      ],
      "metadata": {
        "id": "M3mRoEVszbS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Check duplicates in `top_map` based on state, year, and quarter\n",
        "query = \"\"\"\n",
        "SELECT state, year, quarter, COUNT(*) as occurrences\n",
        "FROM top_map\n",
        "GROUP BY state, year, quarter\n",
        "HAVING COUNT(*) > 1\n",
        "\"\"\"\n",
        "pd.read_sql_query(query, conn)\n"
      ],
      "metadata": {
        "id": "mP4TI_wk0Abb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The PhonePe Pulse dataset provides a rich and structured overview of digital financial activities across India. After loading and exploring the data, we learned the following:\n",
        "\n",
        "Diverse Coverage Across Segments:\n",
        "\n",
        "The dataset is divided into three main segments: aggregated, map, and top tables.\n",
        "\n",
        "Each segment covers different dimensions of PhonePe's ecosystem: transactions, user engagement, and insurance metrics.\n",
        "\n",
        "Temporal & Geographic Depth:\n",
        "\n",
        "Data is available quarter-wise and state-wise, with granular information extending to district and pincode levels.\n",
        "\n",
        "Time ranges from 2018 to 2023, allowing for trend and time-series analysis.\n",
        "\n",
        "Key Metrics Captured:\n",
        "\n",
        "Transaction volume and amount by category (like recharge, peer-to-peer, etc.).\n",
        "\n",
        "User device brands and app open statistics.\n",
        "\n",
        "Insurance transaction patterns.\n",
        "\n",
        "District-wise transaction and user distribution, supporting geospatial analysis.\n",
        "\n",
        "Multiple DataFrames Created:\n",
        "\n",
        "We extracted and cleaned 9 structured DataFrames, such as:\n",
        "\n",
        "df_aggregated_transaction, df_map_user, df_top_map, etc.\n",
        "\n",
        "All datasets have consistent formats with fields like State, Year, Quarter, and corresponding metrics.\n",
        "\n",
        "Data Quality:\n",
        "\n",
        "Most datasets are clean with very few or no missing values.\n",
        "\n",
        "No major duplicates were found across the key tables.\n",
        "\n",
        "Some datasets (like insurance) have fewer entries compared to transactions or users.\n",
        "\n",
        "Potential Use Cases Identified:\n",
        "\n",
        "Transaction trends over time.\n",
        "\n",
        "Device usage patterns across states.\n",
        "\n",
        "Most active districts or pincodes for PhonePe usage.\n",
        "\n",
        "Growth of digital insurance adoption.\n",
        "\n",
        "✅ Overall, the dataset is well-structured, comprehensive, and ready for Exploratory Data Analysis, dashboarding in Streamlit, and deriving business insights across finance, marketing, and user behavior."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "# View columns of all key datasets\n",
        "print(\"🔸 df_aggregated_transaction:\", df_aggregated_transaction.columns.tolist())\n",
        "print(\"🔸 df_aggregated_user:\", df_aggregated_user.columns.tolist())\n",
        "print(\"🔸 df_aggregated_insurance:\", df_aggregated_insurance.columns.tolist())\n",
        "\n",
        "print(\"🔸 df_map_user:\", df_map_user.columns.tolist())\n",
        "print(\"🔸 df_map_map:\", df_map_map.columns.tolist())\n",
        "print(\"🔸 df_map_insurance:\", df_map_insurance.columns.tolist())\n",
        "\n",
        "print(\"🔸 df_top_user:\", df_top_user.columns.tolist())\n",
        "print(\"🔸 df_top_map:\", df_top_map.columns.tolist())\n",
        "print(\"🔸 df_top_insurance:\", df_top_insurance.columns.tolist())\n"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sql version\n",
        "pd.read_sql_query(\"PRAGMA table_info(aggregated_transaction);\", conn)\n",
        "pd.read_sql_query(\"PRAGMA table_info(aggregated_user);\", conn)\n",
        "pd.read_sql_query(\"PRAGMA table_info(aggregated_insurance);\", conn)\n"
      ],
      "metadata": {
        "id": "_qZK_FCH0j52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "# Get descriptive statistics for numerical columns\n",
        "print(\"\\n📊 Descriptive Summary:\")\n",
        "\n",
        "print(\"\\n🔹 df_aggregated_transaction\")\n",
        "print(df_aggregated_transaction.describe())\n",
        "\n",
        "print(\"\\n🔹 df_aggregated_user\")\n",
        "print(df_aggregated_user.describe())\n",
        "\n",
        "print(\"\\n🔹 df_aggregated_insurance\")\n",
        "print(df_aggregated_insurance.describe())\n",
        "\n",
        "print(\"\\n🔹 df_map_user\")\n",
        "print(df_map_user.describe())\n",
        "\n",
        "print(\"\\n🔹 df_map_map\")\n",
        "print(df_map_map.describe())\n",
        "\n",
        "print(\"\\n🔹 df_map_insurance\")\n",
        "print(df_map_insurance.describe())\n",
        "\n",
        "print(\"\\n🔹 df_top_user\")\n",
        "print(df_top_user.describe())\n",
        "\n",
        "print(\"\\n🔹 df_top_map\")\n",
        "print(df_top_map.describe())\n",
        "\n",
        "print(\"\\n🔹 df_top_insurance\")\n",
        "print(df_top_insurance.describe())\n"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe for aggregated_transaction\n",
        "query = \"\"\"\n",
        "SELECT\n",
        "    MIN(Transaction_Amount) AS Min_Amount,\n",
        "    MAX(Transaction_Amount) AS Max_Amount,\n",
        "    AVG(Transaction_Amount) AS Avg_Amount,\n",
        "    SUM(Transaction_Amount) AS Total_Amount,\n",
        "    COUNT(Transaction_Amount) AS Count_Amount,\n",
        "\n",
        "    MIN(Transaction_Count) AS Min_Count,\n",
        "    MAX(Transaction_Count) AS Max_Count,\n",
        "    AVG(Transaction_Count) AS Avg_Count,\n",
        "    SUM(Transaction_Count) AS Total_Count\n",
        "FROM aggregated_transaction;\n",
        "\"\"\"\n",
        "pd.read_sql_query(query, conn)\n"
      ],
      "metadata": {
        "id": "IQthGz1s1BaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pd.read_sql_query(\"PRAGMA table_info(aggregated_user);\", conn)\n"
      ],
      "metadata": {
        "id": "5uVmJ7HU1YsF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"\"\"\n",
        "SELECT\n",
        "    MIN(User_Count) AS Min_User_Count,\n",
        "    MAX(User_Count) AS Max_User_Count,\n",
        "    AVG(User_Count) AS Avg_User_Count,\n",
        "    SUM(User_Count) AS Total_User_Count,\n",
        "    COUNT(User_Count) AS Count_User_Count,\n",
        "\n",
        "    MIN(User_Percentage) AS Min_User_Percentage,\n",
        "    MAX(User_Percentage) AS Max_User_Percentage,\n",
        "    AVG(User_Percentage) AS Avg_User_Percentage,\n",
        "    SUM(User_Percentage) AS Total_User_Percentage\n",
        "FROM aggregated_user;\n",
        "\"\"\"\n",
        "pd.read_sql_query(query, conn)\n"
      ],
      "metadata": {
        "id": "6o2Ifcc71EDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe for aggregated_insurance\n",
        "query = \"\"\"\n",
        "SELECT\n",
        "    MIN(Insurance_Amount) AS Min_Amount,\n",
        "    MAX(Insurance_Amount) AS Max_Amount,\n",
        "    AVG(Insurance_Amount) AS Avg_Amount,\n",
        "    SUM(Insurance_Amount) AS Total_Amount,\n",
        "    COUNT(*) AS Total_Records\n",
        "FROM aggregated_insurance;\n",
        "\"\"\"\n",
        "pd.read_sql_query(query, conn)\n"
      ],
      "metadata": {
        "id": "qXSdiKSs1pLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "📘 aggregated_transaction\n"
      ],
      "metadata": {
        "id": "OrdcwiF33Gcq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Column Name          | Description                                                                 |\n",
        "| -------------------- | --------------------------------------------------------------------------- |\n",
        "| `State`              | Name of the Indian state                                                    |\n",
        "| `Year`               | Year of the transaction                                                     |\n",
        "| `Quarter`            | Quarter of the year (1 to 4)                                                |\n",
        "| `Transaction_Type`   | Type of transaction (e.g., Recharge & bill payments, Peer-to-peer payments) |\n",
        "| `Transaction_Count`  | Number of transactions of the given type in that period                     |\n",
        "| `Transaction_Amount` | Total value (₹) of transactions in that period and type                     |\n"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "📘 aggregated_user\n"
      ],
      "metadata": {
        "id": "NUGYGI2Z3Hoq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Column Name       | Description                                                       |\n",
        "| ----------------- | ----------------------------------------------------------------- |\n",
        "| `State`           | Name of the Indian state                                          |\n",
        "| `Year`            | Year of the data                                                  |\n",
        "| `Quarter`         | Quarter of the year (1 to 4)                                      |\n",
        "| `Brand`           | Mobile phone brand used by users (e.g., Xiaomi, Samsung)          |\n",
        "| `User_Count`      | Number of users using the app with that brand                     |\n",
        "| `User_Percentage` | Percentage of users by brand in the total user count of the state |\n"
      ],
      "metadata": {
        "id": "kjbZUdgo2hAi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "📘 aggregated_insurance\n"
      ],
      "metadata": {
        "id": "JAdAZK7C3KlY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Column Name        | Description                                     |\n",
        "| ------------------ | ----------------------------------------------- |\n",
        "| `State`            | Name of the Indian state                        |\n",
        "| `Year`             | Year of the data                                |\n",
        "| `Quarter`          | Quarter of the year (1 to 4)                    |\n",
        "| `Insurance_Type`   | Type of insurance (e.g., health, vehicle, life) |\n",
        "| `Insurance_Count`  | Number of insurance transactions                |\n",
        "| `Insurance_Amount` | Total value (₹) of insurance transactions       |\n"
      ],
      "metadata": {
        "id": "XUNWqhWq2mj4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "📘 map_user\n"
      ],
      "metadata": {
        "id": "ZAj7MU3H3NXJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Column Name        | Description                                                |\n",
        "| ------------------ | ---------------------------------------------------------- |\n",
        "| `State`            | Name of the Indian state                                   |\n",
        "| `Year`             | Year of the data                                           |\n",
        "| `Quarter`          | Quarter of the year                                        |\n",
        "| `District`         | District within the state                                  |\n",
        "| `Registered_Users` | Total registered PhonePe users in the district             |\n",
        "| `App_Opens`        | Number of times the PhonePe app was opened in the district |\n"
      ],
      "metadata": {
        "id": "R4Ftnggo2p6d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "📘 map_map\n"
      ],
      "metadata": {
        "id": "6nM-u7cw3QGh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Column Name          | Description                                  |\n",
        "| -------------------- | -------------------------------------------- |\n",
        "| `State`              | Name of the Indian state                     |\n",
        "| `Year`               | Year of the data                             |\n",
        "| `Quarter`            | Quarter of the year                          |\n",
        "| `District`           | District name                                |\n",
        "| `Transaction_Count`  | Total number of transactions in the district |\n",
        "| `Transaction_Amount` | Total transaction value (₹) in the district  |\n"
      ],
      "metadata": {
        "id": "fFIhLmvw2szl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "📘 map_insurance\n"
      ],
      "metadata": {
        "id": "hV27kUSG3ScQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Column Name        | Description                                           |\n",
        "| ------------------ | ----------------------------------------------------- |\n",
        "| `State`            | Name of the Indian state                              |\n",
        "| `Year`             | Year of the data                                      |\n",
        "| `Quarter`          | Quarter of the year                                   |\n",
        "| `District`         | District name                                         |\n",
        "| `Insurance_Count`  | Number of insurance transactions in the district      |\n",
        "| `Insurance_Amount` | Total insurance transaction value (₹) in the district |\n"
      ],
      "metadata": {
        "id": "FEHZ_7dl2vcS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "📘 top_user\n"
      ],
      "metadata": {
        "id": "P1PQDeiw3U8T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Column Name        | Description                                |\n",
        "| ------------------ | ------------------------------------------ |\n",
        "| `State`            | Name of the Indian state                   |\n",
        "| `Year`             | Year of the data                           |\n",
        "| `Quarter`          | Quarter of the year                        |\n",
        "| `Pincode`          | Pincode of top PhonePe user locations      |\n",
        "| `Registered_Users` | Number of registered users in that pincode |\n"
      ],
      "metadata": {
        "id": "kfTo30Gn22eo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "📘 top_map\n"
      ],
      "metadata": {
        "id": "ZaWgDKNz3Xes"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Column Name             | Description                                  |\n",
        "| ----------------------- | -------------------------------------------- |\n",
        "| `State`                 | Name of the Indian state                     |\n",
        "| `Year`                  | Year of the data                             |\n",
        "| `Quarter`               | Quarter of the year                          |\n",
        "| `Pincode` or `District` | Top-performing district or pin code          |\n",
        "| `Transaction_Count`     | Number of transactions in the top area       |\n",
        "| `Transaction_Amount`    | Total transaction amount (₹) in the top area |\n"
      ],
      "metadata": {
        "id": "mtxWRgQD25K2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "📘 top_insurance\n"
      ],
      "metadata": {
        "id": "RAi3_-XC3Z9v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Column Name        | Description                                          |\n",
        "| ------------------ | ---------------------------------------------------- |\n",
        "| `State`            | Name of the Indian state                             |\n",
        "| `Year`             | Year of the data                                     |\n",
        "| `Quarter`          | Quarter of the year                                  |\n",
        "| `Insurance_Type`   | Insurance category                                   |\n",
        "| `Insurance_Count`  | Number of transactions                               |\n",
        "| `Insurance_Amount` | Total transaction amount (₹) for that insurance type |\n"
      ],
      "metadata": {
        "id": "wOSLD4_L27_g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "#aggregated_transaction\n",
        "# Unique States\n",
        "pd.read_sql_query(\"SELECT DISTINCT State FROM aggregated_transaction;\", conn)\n",
        "\n",
        "# Unique Years\n",
        "pd.read_sql_query(\"SELECT DISTINCT Year FROM aggregated_transaction;\", conn)\n",
        "\n",
        "# Unique Quarters\n",
        "pd.read_sql_query(\"SELECT DISTINCT Quarter FROM aggregated_transaction;\", conn)\n",
        "\n",
        "# Unique Transaction Types\n",
        "pd.read_sql_query(\"SELECT DISTINCT Transaction_Type FROM aggregated_transaction;\", conn)\n"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#aggregated_user\n",
        "# Unique Brands\n",
        "pd.read_sql_query(\"SELECT DISTINCT Brand FROM aggregated_user;\", conn)\n",
        "\n",
        "# Unique Years\n",
        "pd.read_sql_query(\"SELECT DISTINCT Year FROM aggregated_user;\", conn)\n",
        "\n",
        "# Unique States\n",
        "pd.read_sql_query(\"SELECT DISTINCT State FROM aggregated_user;\", conn)\n",
        "\n"
      ],
      "metadata": {
        "id": "NngLkPKA3qaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#aggregated_insurance\n",
        "# Unique Insurance Types\n",
        "pd.read_sql_query(\"SELECT DISTINCT Insurance_Type FROM aggregated_insurance;\", conn)\n",
        "\n",
        "# Unique States\n",
        "pd.read_sql_query(\"SELECT DISTINCT State FROM aggregated_insurance;\", conn)\n"
      ],
      "metadata": {
        "id": "ypDoUNuT3x_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.read_sql_query(\"SELECT COUNT(DISTINCT Transaction_Type) AS Unique_Types FROM aggregated_transaction;\", conn)\n"
      ],
      "metadata": {
        "id": "glSndcdA4CMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#map_user\n",
        "# Unique States\n",
        "pd.read_sql_query(\"SELECT DISTINCT State FROM map_user;\", conn)\n",
        "\n",
        "# Unique Years\n",
        "pd.read_sql_query(\"SELECT DISTINCT Year FROM map_user;\", conn)\n",
        "\n",
        "# Unique Quarters\n",
        "pd.read_sql_query(\"SELECT DISTINCT Quarter FROM map_user;\", conn)\n",
        "\n",
        "# Unique Districts\n",
        "pd.read_sql_query(\"SELECT DISTINCT District FROM map_user;\", conn)\n",
        "\n"
      ],
      "metadata": {
        "id": "UiNWqGhm4iUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#map_map\n",
        "# Unique States\n",
        "pd.read_sql_query(\"SELECT DISTINCT State FROM map_map;\", conn)\n",
        "\n",
        "# Unique Districts\n",
        "pd.read_sql_query(\"SELECT DISTINCT District FROM map_map;\", conn)\n",
        "\n",
        "# Unique Years\n",
        "pd.read_sql_query(\"SELECT DISTINCT Year FROM map_map;\", conn)\n",
        "\n",
        "# Unique Quarters\n",
        "pd.read_sql_query(\"SELECT DISTINCT Quarter FROM map_map;\", conn)\n"
      ],
      "metadata": {
        "id": "VISMWc3C4nbM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#map_insurance\n",
        "# Unique States\n",
        "pd.read_sql_query(\"SELECT DISTINCT State FROM map_insurance;\", conn)\n",
        "\n",
        "# Unique Districts\n",
        "pd.read_sql_query(\"SELECT DISTINCT District FROM map_insurance;\", conn)\n",
        "\n",
        "# Unique Years\n",
        "pd.read_sql_query(\"SELECT DISTINCT Year FROM map_insurance;\", conn)\n",
        "\n",
        "# Unique Quarters\n",
        "pd.read_sql_query(\"SELECT DISTINCT Quarter FROM map_insurance;\", conn)\n"
      ],
      "metadata": {
        "id": "rSi_gOSw4sY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#top_user\n",
        "# Unique States\n",
        "pd.read_sql_query(\"SELECT DISTINCT State FROM top_user;\", conn)\n",
        "\n",
        "# Unique Pincodes\n",
        "# Unique Names (likely Pincodes or Districts)\n",
        "pd.read_sql_query(\"SELECT DISTINCT Name FROM top_user;\", conn)\n",
        "\n",
        "# Unique Years\n",
        "pd.read_sql_query(\"SELECT DISTINCT Year FROM top_user;\", conn)\n",
        "\n",
        "# Unique Quarters\n",
        "pd.read_sql_query(\"SELECT DISTINCT Quarter FROM top_user;\", conn)\n"
      ],
      "metadata": {
        "id": "ziwHbFlB4xp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#top_map\n",
        "# Unique States\n",
        "pd.read_sql_query(\"SELECT DISTINCT State FROM top_map;\", conn)\n",
        "\n",
        "# Unique Districts or Pincodes\n",
        "# Unique Districts or Pincodes (Stored under 'Name')\n",
        "pd.read_sql_query(\"SELECT DISTINCT Name FROM top_map;\", conn)\n",
        "\n",
        "# Unique Years\n",
        "pd.read_sql_query(\"SELECT DISTINCT Year FROM top_map;\", conn)\n",
        "\n",
        "# Unique Quarters\n",
        "pd.read_sql_query(\"SELECT DISTINCT Quarter FROM top_map;\", conn)\n"
      ],
      "metadata": {
        "id": "COIrEpmV87ft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#top_insurance\n",
        "# Unique States\n",
        "pd.read_sql_query(\"SELECT DISTINCT State FROM top_insurance;\", conn)\n",
        "\n",
        "# Unique Insurance Types\n",
        "pd.read_sql_query(\"SELECT DISTINCT Name FROM top_insurance;\", conn)\n",
        "\n",
        "# Unique Years\n",
        "pd.read_sql_query(\"SELECT DISTINCT Year FROM top_insurance;\", conn)\n",
        "\n",
        "# Unique Quarters\n",
        "pd.read_sql_query(\"SELECT DISTINCT Quarter FROM top_insurance;\", conn)\n"
      ],
      "metadata": {
        "id": "J3KEMaVb9aCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "# Load all tables into DataFrames\n",
        "df_agg_trans     = pd.read_sql_query(\"SELECT * FROM aggregated_transaction;\", conn)\n",
        "df_agg_user      = pd.read_sql_query(\"SELECT * FROM aggregated_user;\", conn)\n",
        "df_agg_ins       = pd.read_sql_query(\"SELECT * FROM aggregated_insurance;\", conn)\n",
        "df_map_user      = pd.read_sql_query(\"SELECT * FROM map_user;\", conn)\n",
        "df_map_map       = pd.read_sql_query(\"SELECT * FROM map_map;\", conn)\n",
        "df_map_ins       = pd.read_sql_query(\"SELECT * FROM map_insurance;\", conn)\n",
        "df_top_user      = pd.read_sql_query(\"SELECT * FROM top_user;\", conn)\n",
        "df_top_map       = pd.read_sql_query(\"SELECT * FROM top_map;\", conn)\n",
        "df_top_ins       = pd.read_sql_query(\"SELECT * FROM top_insurance;\", conn)\n",
        "\n"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize column names\n",
        "df_agg_trans.rename(columns={\n",
        "    'Transaction_Type': 'TransactionType',\n",
        "    'Transaction_Count': 'TransactionCount',\n",
        "    'Transaction_Amount': 'TransactionAmount'\n",
        "}, inplace=True)\n",
        "\n",
        "df_agg_user.rename(columns={\n",
        "    'User_Count': 'UserCount',\n",
        "    'User_Percentage': 'UserPercentage'\n",
        "}, inplace=True)\n",
        "\n",
        "df_agg_ins.rename(columns={\n",
        "    'Insurance_Type': 'InsuranceType',\n",
        "    'Insurance_Count': 'InsuranceCount',\n",
        "    'Insurance_Amount': 'InsuranceAmount'\n",
        "}, inplace=True)\n",
        "\n",
        "df_map_user.rename(columns={\n",
        "    'Registered_Users': 'RegisteredUsers',\n",
        "    'App_Opens': 'AppOpens'\n",
        "}, inplace=True)\n",
        "\n",
        "df_map_map.rename(columns={\n",
        "    'Transaction_Count': 'TransactionCount',\n",
        "    'Transaction_Amount': 'TransactionAmount'\n",
        "}, inplace=True)\n",
        "\n",
        "df_map_ins.rename(columns={\n",
        "    'Insurance_Count': 'InsuranceCount',\n",
        "    'Insurance_Amount': 'InsuranceAmount'\n",
        "}, inplace=True)\n",
        "\n",
        "df_top_user.rename(columns={\n",
        "    'Registered_Users': 'RegisteredUsers',\n",
        "    'Name': 'Pincode'\n",
        "}, inplace=True)\n",
        "\n",
        "df_top_map.rename(columns={\n",
        "    'Transaction_Count': 'TransactionCount',\n",
        "    'Transaction_Amount': 'TransactionAmount',\n",
        "    'Name': 'PincodeOrDistrict'\n",
        "}, inplace=True)\n",
        "\n",
        "df_top_ins.rename(columns={\n",
        "    'Insurance_Count': 'InsuranceCount',\n",
        "    'Insurance_Amount': 'InsuranceAmount'\n",
        "}, inplace=True)\n"
      ],
      "metadata": {
        "id": "qzLo_Lhu-J5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tables = {\n",
        "    'df_agg_trans': df_agg_trans,\n",
        "    'df_agg_user': df_agg_user,\n",
        "    'df_agg_ins': df_agg_ins,\n",
        "    'df_map_user': df_map_user,\n",
        "    'df_map_map': df_map_map,\n",
        "    'df_map_ins': df_map_ins,\n",
        "    'df_top_user': df_top_user,\n",
        "    'df_top_map': df_top_map,\n",
        "    'df_top_ins': df_top_ins,\n",
        "}\n",
        "\n",
        "# Print missing values\n",
        "for name, df in tables.items():\n",
        "    print(f\"🔍 Missing in {name}:\\n\", df.isnull().sum(), \"\\n\")\n",
        "\n",
        "# Drop missing rows (you may choose to impute instead)\n",
        "for df in tables.values():\n",
        "    df.dropna(inplace=True)\n"
      ],
      "metadata": {
        "id": "Na32SBkQ-Nbt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for df in tables.values():\n",
        "    for col in ['Year', 'Quarter']:\n",
        "        if col in df.columns:\n",
        "            df[col] = df[col].astype(int)\n"
      ],
      "metadata": {
        "id": "fvunsbS0-RVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for df in tables.values():\n",
        "    if 'Year' in df.columns and 'Quarter' in df.columns:\n",
        "        df['Period'] = df['Year'].astype(str) + \"-Q\" + df['Quarter'].astype(str)\n"
      ],
      "metadata": {
        "id": "DQ58nVQ--zWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"✅ Sample from df_agg_trans:\\n\", df_agg_trans.head())\n",
        "print(\"✅ Sample from df_map_user:\\n\", df_map_user.head())\n",
        "print(\"✅ Sample from df_top_user:\\n\", df_top_user.head())\n"
      ],
      "metadata": {
        "id": "hvHVER6o-1sx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "During the data wrangling and preparation phase, the following key manipulations were performed to make the PhonePe Pulse dataset analysis-ready:\n",
        "\n",
        "1. **Loaded All 9 Tables from SQL Database:**\n",
        "\n",
        "   * Tables: `aggregated_transaction`, `aggregated_user`, `aggregated_insurance`, `map_user`, `map_map`, `map_insurance`, `top_user`, `top_map`, `top_insurance`.\n",
        "\n",
        "2. **Renamed Columns for Consistency:**\n",
        "\n",
        "   * Standardized column names like `Transaction_Type` to `TransactionType`, `User_Count` to `UserCount`, etc.\n",
        "   * Converted ambiguous column names such as `Name` to more meaningful ones like `Pincode` or `District`.\n",
        "\n",
        "3. **Handled Missing Values:**\n",
        "\n",
        "   * Identified missing values in all tables.\n",
        "   * Used `.dropna()` to remove rows with critical null values for cleaner analysis.\n",
        "   * Optionally, missing values could be imputed based on historical or group-wise means if needed.\n",
        "\n",
        "4. **Converted Data Types:**\n",
        "\n",
        "   * Ensured that key time-based fields like `Year` and `Quarter` are stored as integers for plotting and filtering.\n",
        "\n",
        "5. **Created a Combined `Period` Column:**\n",
        "\n",
        "   * Created a new `Period` column in `YYYY-QX` format to easily perform time-series analysis.\n",
        "\n",
        "6. **Verified Data Integrity and Uniqueness:**\n",
        "\n",
        "   * Checked for and removed duplicate records if any.\n",
        "   * Explored `DISTINCT` values in each categorical column to ensure data distribution is clean and logical.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Aggregate total transaction amount per state\n",
        "top_states = df_agg_trans.groupby('State')['TransactionAmount'].sum().sort_values(ascending=False).head(10)\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(12,6))\n",
        "sns.barplot(x=top_states.values, y=top_states.index, palette='Blues_r')\n",
        "plt.title('Top 10 States by Total Transaction Amount', fontsize=16)\n",
        "plt.xlabel('Total Transaction Amount (INR)', fontsize=12)\n",
        "plt.ylabel('State', fontsize=12)\n",
        "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Highlight the states contributing the most in terms of transaction value.\n",
        "\n",
        "Identify regional trends in digital payment adoption.\n",
        "\n",
        "Enable geo-targeting of product and marketing strategies."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "States like Maharashtra, Karnataka, Telangana,Uttar Pradesh lead the digital payment space.\n",
        "\n",
        "This suggests strong smartphone and internet penetration, along with trust in PhonePe as a transaction platform."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ Positive Impact:\n",
        "\n",
        "Helps focus strategic efforts on high-value markets for launching new features (like credit/insurance).\n",
        "\n",
        "Influences ad targeting and regional partnerships to grow further in those states.\n",
        "\n",
        "⚠️ Negative Growth Indicator:\n",
        "\n",
        "Some states like North Eastern regions, Bihar, Jharkhand are missing in the top 10 — indicating low adoption.\n",
        "\n",
        "Justification: This may be due to infrastructural challenges, lack of awareness, or limited POS network — which can be addressed with targeted awareness campaigns or UPI push efforts."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "# Aggregate total number of transactions per state\n",
        "top_txn_states = df_agg_trans.groupby('State')['TransactionCount'].sum().sort_values(ascending=False).head(10)\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(12,6))\n",
        "sns.barplot(x=top_txn_states.values, y=top_txn_states.index, palette='Greens_r')\n",
        "plt.title('Top 10 States by Total Number of Transactions', fontsize=16)\n",
        "plt.xlabel('Total Transaction Count', fontsize=12)\n",
        "plt.ylabel('State', fontsize=12)\n",
        "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Showing user activity levels (how often users transact).\n",
        "\n",
        "Revealing not just big-ticket states, but frequent transacting states.\n",
        "\n",
        "Providing additional context for user engagement analysis."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "States like Uttar Pradesh, Maharashtra, Karnataka again appear on top, meaning they not only transact in high amounts but also frequently.\n",
        "\n",
        "Some high-amount states may not have the highest frequency, indicating fewer but higher-value transactions.\n",
        "\n"
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ Positive Impact:\n",
        "\n",
        "High-frequency regions are great targets for subscription models, in-app offers, and gamified engagement tools.\n",
        "\n",
        "These states may also have more mature digital payment users, ideal for pilot launches of new features (like UPI Lite or PayLater).\n",
        "\n",
        "⚠️ Negative Growth Indicator:\n",
        "\n",
        "Low-frequency but high-value regions may be under-utilizing the app for daily payments — pointing to an opportunity for behavioral nudges or education campaigns.\n",
        "\n"
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "# Aggregate total transaction count by Year-Quarter\n",
        "quarterly_txn = df_agg_trans.groupby(['Year', 'Quarter'])['TransactionCount'].sum().reset_index()\n",
        "quarterly_txn['Period'] = quarterly_txn['Year'].astype(str) + \"-Q\" + quarterly_txn['Quarter'].astype(str)\n",
        "\n",
        "# Sort by period\n",
        "quarterly_txn.sort_values(by=['Year', 'Quarter'], inplace=True)\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(14,6))\n",
        "sns.lineplot(x='Period', y='TransactionCount', data=quarterly_txn, marker='o', color='purple')\n",
        "plt.title('Quarterly Growth in Transaction Volume (India)', fontsize=16)\n",
        "plt.xlabel('Period (Year-Quarter)', fontsize=12)\n",
        "plt.ylabel('Total Transactions', fontsize=12)\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To visualize trends over time and check for seasonality, growth spurts, or dips.\n",
        "\n",
        "Helps answer questions like: Is PhonePe adoption growing steadily? Are there any quarters of slow growth?\n",
        "\n",
        "Great for showcasing business health over time.\n",
        "\n"
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is a clear and consistent upward trend in transaction volume quarter after quarter.\n",
        "\n",
        "Minor dips may be observed in some quarters (e.g., early pandemic) but recovery is quick.\n",
        "\n",
        "Shows strong adoption and trust built over time in PhonePe."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ Positive Impact:\n",
        "\n",
        "Confirms a healthy and growing user base.\n",
        "\n",
        "Encourages further investment in infrastructure and user acquisition.\n",
        "\n",
        "⚠️ Negative Insight:\n",
        "\n",
        "If dips appear (like during lockdowns), they highlight vulnerability to external shocks.\n",
        "\n",
        "Suggests need for service diversification (insurance, lending, etc.) to smooth revenue across business lines."
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "# Aggregate total registered users by Year-Quarter\n",
        "user_growth = df_map_user.groupby(['Year', 'Quarter'])['RegisteredUsers'].sum().reset_index()\n",
        "user_growth['Period'] = user_growth['Year'].astype(str) + \"-Q\" + user_growth['Quarter'].astype(str)\n",
        "\n",
        "# Sort by period\n",
        "user_growth.sort_values(by=['Year', 'Quarter'], inplace=True)\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(14,6))\n",
        "sns.lineplot(x='Period', y='RegisteredUsers', data=user_growth, marker='o', color='darkgreen')\n",
        "plt.title('Quarterly Growth in Registered Users (India)', fontsize=16)\n",
        "plt.xlabel('Period (Year-Quarter)', fontsize=12)\n",
        "plt.ylabel('Total Registered Users', fontsize=12)\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To analyze PhonePe’s user base expansion over time.\n",
        "\n",
        "Helps stakeholders see how quickly and steadily the platform is acquiring users.\n",
        "\n",
        "Detects spikes due to promotional campaigns or major product launches."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Consistent growth in registered users, especially from mid-2021 onwards.\n",
        "\n",
        "No major drops, suggesting strong user retention and acquisition strategies.\n",
        "\n",
        "Potential surge in Q1 2022 possibly due to cashback schemes or UPI 123Pay rollout.\n",
        "\n"
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ Positive Impact:\n",
        "\n",
        "Shows PhonePe’s success in penetrating deeper markets.\n",
        "\n",
        "Useful to forecast server capacity needs, plan for customer support, and regional marketing.\n",
        "\n",
        "⚠️ Negative Insight:\n",
        "\n",
        "If any plateau is observed, it could signal market saturation in certain states — prompting need to pivot toward cross-selling financial products (insurance, mutual funds, gold, etc.)."
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import pandas as pd\n",
        "\n",
        "# Connect to your SQLite database\n",
        "conn = sqlite3.connect('phonepe.db')  # or ':memory:' if in-memory\n",
        "\n",
        "# Load the aggregated_insurance table into a DataFrame\n",
        "df_agg_insurance = pd.read_sql(\"SELECT * FROM aggregated_insurance\", conn)\n"
      ],
      "metadata": {
        "id": "wVBrwlp_hGRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aggregate total insurance premium per state\n",
        "top_insurance_states = df_agg_insurance.groupby('State')['Insurance_Amount'].sum().sort_values(ascending=False).head(10)\n",
        "\n",
        "# Plotting\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "sns.barplot(x=top_insurance_states.values, y=top_insurance_states.index, palette='Reds_r')\n",
        "plt.title('Top 10 States by Total Insurance Premium Collected', fontsize=16)\n",
        "plt.xlabel('Total Insurance Amount (INR)', fontsize=12)\n",
        "plt.ylabel('State', fontsize=12)\n",
        "plt.grid(axis='x', linestyle='--', alpha=0.6)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Insurance adoption is still nascent in India, and PhonePe’s push in this area is vital.\n",
        "\n",
        "This chart shows which states are most open to digital insurance services, helping with product and partnership decisions.\n",
        "\n"
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "States like Maharashtra, Karnataka, Tamil Nadu, and Delhi lead in premium collections.\n",
        "\n",
        "These are digitally mature states with higher financial awareness.\n",
        "\n",
        "Northeastern and some central Indian states are significantly underrepresented."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ Positive Impact:\n",
        "\n",
        "Shows successful traction in Tier-1 regions.\n",
        "\n",
        "Indicates regions where PhonePe can introduce advanced insurance products (e.g., health + term insurance bundles).\n",
        "\n",
        "⚠️ Negative Insight:\n",
        "\n",
        "Low uptake in some regions may indicate a lack of insurance literacy, mistrust in digital products, or absence of personalized offerings.\n",
        "\n",
        "Suggests the need for localized marketing and vernacular support.\n",
        "\n"
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_map_user.columns\n"
      ],
      "metadata": {
        "id": "sCkCh4pOFPn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "# Aggregate total App Opens by State\n",
        "top_app_opens = df_map_user.groupby('State')['AppOpens'].sum().sort_values(ascending=False).head(10)\n",
        "\n",
        "# Plotting\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "sns.barplot(x=top_app_opens.values, y=top_app_opens.index, palette='Blues_r')\n",
        "plt.title('Top 10 States by Total App Opens', fontsize=16)\n",
        "plt.xlabel('App Opens Count', fontsize=12)\n",
        "plt.ylabel('State', fontsize=12)\n",
        "plt.grid(axis='x', linestyle='--', alpha=0.6)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To measure engagement intensity, not just installations or registrations.\n",
        "\n",
        "App opens are a behavioral metric showing real, ongoing interaction with PhonePe.\n",
        "\n",
        "Helps identify states with high user retention and frequency of usage.\n",
        "\n"
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "States like Maharashtra, Karnataka, and Uttar Pradesh again lead, confirming both scale and engagement.\n",
        "\n",
        "Some smaller states might rank high if users are more active, showing quality of user base.\n",
        "\n"
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ Positive Insight:\n",
        "\n",
        "States with high app opens are ideal candidates for launching new features, beta programs, and upselling financial products.\n",
        "\n",
        "⚠️ Negative Insight:\n",
        "\n",
        "If some high-registration states show low app opens, it signals poor engagement — possibly due to user friction, slow app performance, or low local relevance.\n",
        "\n"
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "# Aggregate required data from both datasets\n",
        "user_by_state = df_map_user.groupby('State')['RegisteredUsers'].sum().reset_index()\n",
        "txn_by_state = df_agg_trans.groupby('State')['TransactionCount'].sum().reset_index()\n",
        "\n",
        "# Merge on 'State'\n",
        "merged_df = pd.merge(user_by_state, txn_by_state, on='State')\n",
        "\n",
        "# Plotting the relationship\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.scatterplot(data=merged_df, x='RegisteredUsers', y='TransactionCount', hue='State', palette='tab20', s=100)\n",
        "plt.title('Registered Users vs Transaction Count (State-wise)', fontsize=16)\n",
        "plt.xlabel('Registered Users', fontsize=12)\n",
        "plt.ylabel('Total Transaction Count', fontsize=12)\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To analyze whether states with more users actually contribute more transactions.\n",
        "\n",
        "Helps test if user volume = usage, or if there are states with inactive users.\n",
        "\n"
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There’s generally a positive linear correlation: states with higher registered users tend to have higher transaction counts.\n",
        "\n",
        "A few states might have large user bases but low transactions — this reveals engagement gaps.\n",
        "\n",
        "Others with lower users but high transactions suggest high-value or frequent users."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ Positive Impact:\n",
        "\n",
        "Enables targeting campaigns in states where user engagement is already high.\n",
        "\n",
        "⚠️ Negative Insight:\n",
        "\n",
        "States with high users but low transactions may need education, UX improvements, or localized features.\n",
        "\n"
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "# Aggregate insurance data by State\n",
        "insurance_statewise = df_agg_insurance.groupby('State')[['Insurance_Count', 'Insurance_Amount']].sum().reset_index()\n",
        "\n",
        "# Plot Bubble Chart\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(14,8))\n",
        "scatter = plt.scatter(\n",
        "    insurance_statewise['Insurance_Count'],\n",
        "    insurance_statewise['Insurance_Amount'],\n",
        "    s=insurance_statewise['Insurance_Amount'] / 10000,  # Bubble size\n",
        "    alpha=0.6,\n",
        "    c='purple',\n",
        "    edgecolors='w'\n",
        ")\n",
        "\n",
        "for i in range(len(insurance_statewise)):\n",
        "    plt.text(\n",
        "        insurance_statewise['Insurance_Count'][i],\n",
        "        insurance_statewise['Insurance_Amount'][i],\n",
        "        insurance_statewise['State'][i],\n",
        "        fontsize=8\n",
        "    )\n",
        "\n",
        "plt.title('State-wise Insurance Count vs Amount (Bubble Size = Amount)', fontsize=16)\n",
        "plt.xlabel('Insurance Count', fontsize=12)\n",
        "plt.ylabel('Insurance Amount (INR)', fontsize=12)\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To analyze how insurance product sales (count) relate to total premium collected (amount) across states.\n",
        "\n",
        "Bubble charts give a 3-dimensional feel, useful for identifying outliers and disproportions.\n",
        "\n",
        "Helps us answer: Are some states selling many small-ticket policies while others sell fewer but high-value ones?\n",
        "\n"
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some states have high count but low amount, indicating low-ticket insurance sales (e.g., travel or micro-insurance).\n",
        "\n",
        "Others have low count but high amount, suggesting popularity of high-value policies (e.g., health or term life).\n",
        "\n",
        "A few high performers are balanced with both high count and high amount — PhonePe should target these for upselling and cross-selling."
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ Positive Insight:\n",
        "\n",
        "Helps refine insurance product strategy by region.\n",
        "\n",
        "Identify bulk buyers vs quality buyers.\n",
        "\n",
        "⚠️ Negative Insight:\n",
        "\n",
        "States with high user base but low insurance activity show missed revenue opportunities.\n",
        "\n",
        "Action: Launch awareness campaigns or simplify onboarding for those users."
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_map_map.columns\n"
      ],
      "metadata": {
        "id": "j3yilI_HGoNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code\n",
        "# Aggregate transaction amount by district\n",
        "top_districts_txn = df_map_map.groupby('District')['TransactionAmount'].sum().sort_values(ascending=False).head(10)\n",
        "\n",
        "# Plotting\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "sns.barplot(x=top_districts_txn.values, y=top_districts_txn.index, palette='viridis')\n",
        "plt.title('Top 10 Districts by Transaction Amount', fontsize=16)\n",
        "plt.xlabel('Total Transaction Amount (INR)', fontsize=12)\n",
        "plt.ylabel('District', fontsize=12)\n",
        "plt.grid(axis='x', linestyle='--', alpha=0.6)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "District-level insights help refine hyperlocal marketing and expansion strategies.\n",
        "\n",
        "Helps PhonePe identify districts with highest economic activity or digital payment adoption.\n",
        "\n"
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Major urban hubs (e.g., Bengaluru, Mumbai, Hyderabad) likely dominate transaction amounts.\n",
        "\n",
        "Some unexpected Tier-2 or Tier-3 cities might also feature due to regional fintech adoption, showing growth potential."
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ Positive Impact:\n",
        "\n",
        "Top-performing districts can be prioritized for premium services, insurance bundles, or investment tools.\n",
        "\n",
        "⚠️ Negative Insight:\n",
        "\n",
        "If some districts are large in population but show low transaction amounts, it suggests underpenetration, requiring education campaigns or regional partnerships.\n",
        "\n"
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_agg_trans.columns\n"
      ],
      "metadata": {
        "id": "eq7rjTVaHI5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 visualization code\n",
        "# Aggregate transaction amount per year and quarter\n",
        "quarterly_trend = df_agg_trans.groupby(['Year', 'Quarter'])['TransactionAmount'].sum().reset_index()\n",
        "\n",
        "# Combine year and quarter for x-axis\n",
        "quarterly_trend['Period'] = quarterly_trend['Year'].astype(str) + '-Q' + quarterly_trend['Quarter'].astype(str)\n",
        "\n",
        "# Sort the period correctly\n",
        "quarterly_trend = quarterly_trend.sort_values(by=['Year', 'Quarter'])\n",
        "\n",
        "# Plotting\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(14,6))\n",
        "plt.plot(quarterly_trend['Period'], quarterly_trend['TransactionAmount'], marker='o', linestyle='-', color='darkorange')\n",
        "plt.title('Quarterly Transaction Amount Trend', fontsize=16)\n",
        "plt.xlabel('Year-Quarter', fontsize=12)\n",
        "plt.ylabel('Transaction Amount (INR)', fontsize=12)\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To uncover seasonality patterns — are there spikes in usage during festivals, financial quarters, etc.?\n",
        "\n",
        "Helps understand user behavior over time and track growth of PhonePe."
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Typically, spikes may occur in Q3-Q4 (Oct-Mar), correlating with festive seasons, year-end sales, and bonus payouts.\n",
        "\n",
        "Post-COVID periods may show accelerated digital adoption.\n",
        "\n",
        "Any dips in quarters could correlate with policy changes or technical disruptions."
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "JMzcOPDDphqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ Positive Insight:\n",
        "\n",
        "Marketing & cashback offers can be timed during expected spikes to maximize ROI.\n",
        "\n",
        "Financial products like insurance or loans can be promoted in high-activity quarters.\n",
        "\n",
        "⚠️ Negative Insight:\n",
        "\n",
        "If a specific quarter consistently underperforms, it may indicate external friction, which can be resolved with feature optimizations or regional offers."
      ],
      "metadata": {
        "id": "R4Ka1PC2phqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 11 visualization code\n",
        "# Aggregate total transaction count by transaction type/category\n",
        "txn_by_category = df_agg_trans.groupby('TransactionType')['TransactionCount'].sum().sort_values(ascending=False)\n",
        "\n",
        "# Plotting\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.barplot(x=txn_by_category.values, y=txn_by_category.index, palette='coolwarm')\n",
        "plt.title('Most Popular Transaction Categories by Volume', fontsize=16)\n",
        "plt.xlabel('Total Transaction Count', fontsize=12)\n",
        "plt.ylabel('Transaction Category', fontsize=12)\n",
        "plt.grid(axis='x', linestyle='--', alpha=0.6)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "X_VqEhTip1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To understand user intent behind transactions (e.g., recharge, bills, UPI transfers, merchant payments).\n",
        "\n",
        "Category analysis guides product feature enhancements and partner onboarding."
      ],
      "metadata": {
        "id": "-vsMzt_np1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Categories like Recharge & Bill Payments, Peer-to-Peer Transfers, and Merchant Payments usually dominate.\n",
        "\n",
        "Less popular ones (e.g., Financial Services or Subscriptions) could be growth areas with the right incentives.\n",
        "\n"
      ],
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ Positive Insight:\n",
        "\n",
        "Popular categories are strong pillars — PhonePe can double down on partnerships and UX improvements here.\n",
        "\n",
        "⚠️ Negative Insight:\n",
        "\n",
        "Low usage in some categories may indicate complex workflows or lack of user awareness — an opportunity for UI simplification and in-app nudges."
      ],
      "metadata": {
        "id": "druuKYZpp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 12 visualization code\n",
        "# Aggregate insurance amount by insurance type\n",
        "insurance_by_type = df_agg_insurance.groupby('Insurance_Type')['Insurance_Amount'].sum().sort_values(ascending=False)\n",
        "\n",
        "# Plotting\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.barplot(x=insurance_by_type.values, y=insurance_by_type.index, palette='magma')\n",
        "plt.title('Total Insurance Amount by Type', fontsize=16)\n",
        "plt.xlabel('Total Insurance Amount (INR)', fontsize=12)\n",
        "plt.ylabel('Insurance Type', fontsize=12)\n",
        "plt.grid(axis='x', linestyle='--', alpha=0.6)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "ylSl6qgtp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To discover which insurance products (like health, accident, life, travel) are most favored by users.\n",
        "\n",
        "Enables PhonePe to focus marketing efforts on high-performing or underperforming products.\n",
        "\n"
      ],
      "metadata": {
        "id": "m2xqNkiQp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ZWILFDl5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One or two insurance types typically dominate — e.g., Health or Term Insurance may have higher premiums.\n",
        "\n",
        "Niche types like Travel or Cyber Insurance may have fewer buyers but fast growth potential."
      ],
      "metadata": {
        "id": "x-lUsV2mp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "M7G43BXep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ Positive Insight:\n",
        "\n",
        "Strong-selling insurance types should receive continued feature investment and partner expansions.\n",
        "\n",
        "Successful categories can serve as anchor products to cross-sell others.\n",
        "\n",
        "⚠️ Negative Insight:\n",
        "\n",
        "Low-performing types may indicate low awareness or poor product-market fit — offering custom bundles or better user education could help.\n",
        "\n"
      ],
      "metadata": {
        "id": "5wwDJXsLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 13"
      ],
      "metadata": {
        "id": "Ag9LCva-p1cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 13 visualization code\n",
        "# Aggregate total registered users by state\n",
        "state_user_counts = df_map_user.groupby('State')['RegisteredUsers'].sum().sort_values(ascending=False)\n",
        "\n",
        "# Plotting\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(12,8))\n",
        "sns.barplot(x=state_user_counts.values, y=state_user_counts.index, palette='cubehelix')\n",
        "plt.title('Total Registered Users by State', fontsize=16)\n",
        "plt.xlabel('Registered Users', fontsize=12)\n",
        "plt.ylabel('State', fontsize=12)\n",
        "plt.grid(axis='x', linestyle='--', alpha=0.6)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "EUfxeq9-p1cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "E6MkPsBcp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To evaluate PhonePe’s reach across different regions.\n",
        "\n",
        "Helps identify high penetration states and regions that may need more awareness or acquisition strategies."
      ],
      "metadata": {
        "id": "V22bRsFWp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "2cELzS2fp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "States like Maharashtra, Karnataka, Tamil Nadu, Uttar Pradesh often show high user registrations.\n",
        "\n",
        "Less populous or remote states may show lower adoption, indicating potential for growth with regional onboarding campaigns."
      ],
      "metadata": {
        "id": "ozQPc2_Ip1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "3MPXvC8up1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ Positive Insight:\n",
        "\n",
        "Focus more value-added services (insurance, loans) in states with a high user base to increase LTV (Lifetime Value).\n",
        "\n",
        "States with large base can be used as test markets for new features.\n",
        "\n",
        "⚠️ Negative Insight:\n",
        "\n",
        "Underperforming regions in terms of user count could be bottlenecks to all services — time to optimize marketing, regional language support, or simplify KYC."
      ],
      "metadata": {
        "id": "GL8l1tdLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 14 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "# Combine numerical fields from relevant tables (adjust columns if different in your actual DB)\n",
        "df_corr = pd.DataFrame({\n",
        "    'Transaction_Amount': df_agg_trans.groupby('State')['TransactionAmount'].sum(),\n",
        "    'Transaction_Count': df_agg_trans.groupby('State')['TransactionCount'].sum(),\n",
        "    'Insurance_Amount': df_agg_insurance.groupby('State')['Insurance_Amount'].sum(),\n",
        "    'Insurance_Count': df_agg_insurance.groupby('State')['Insurance_Count'].sum(),\n",
        "    'Registered_Users': df_map_user.groupby('State')['RegisteredUsers'].sum(),\n",
        "    'App_Opens': df_map_user.groupby('State')['AppOpens'].sum()\n",
        "}).reset_index(drop=True)\n",
        "\n",
        "# Compute correlation matrix\n",
        "corr_matrix = df_corr.corr()\n",
        "\n",
        "# Plot heatmap\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10,7))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='YlGnBu', linewidths=0.5, fmt=\".2f\")\n",
        "plt.title('Correlation Heatmap of Key Variables', fontsize=16)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Correlation Heatmaps are essential for:\n",
        "\n",
        "Detecting highly correlated features (which may be redundant).\n",
        "\n",
        "Understanding which features move together, helping business prioritize metrics.\n",
        "\n",
        "Feeding better data into ML models (avoiding multicollinearity).\n",
        "\n"
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "High positive correlation between Transaction Amount and Transaction Count ✅\n",
        "\n",
        "Strong link between Registered Users and App Opens ✅\n",
        "\n",
        "Moderate correlation between Insurance Metrics and user base 📉"
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 15 - Pair Plot"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair Plot visualization code\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Select numeric features across states for the plot\n",
        "df_pair = pd.DataFrame({\n",
        "    'Transaction_Amount': df_agg_trans.groupby('State')['TransactionAmount'].sum().values,\n",
        "    'Transaction_Count': df_agg_trans.groupby('State')['TransactionCount'].sum().values,\n",
        "    'Insurance_Amount': df_agg_insurance.groupby('State')['Insurance_Amount'].sum().values,\n",
        "    'Insurance_Count': df_agg_insurance.groupby('State')['Insurance_Count'].sum().values,\n",
        "    'Registered_Users': df_map_user.groupby('State')['RegisteredUsers'].sum().values,\n",
        "    'App_Opens': df_map_user.groupby('State')['AppOpens'].sum().values\n",
        "})\n",
        "\n",
        "# Drop NA values (if any)\n",
        "df_pair.dropna(inplace=True)\n",
        "\n",
        "# Plot\n",
        "sns.pairplot(df_pair, corner=True, diag_kind='kde', plot_kws={'alpha': 0.6, 's': 60})\n",
        "plt.suptitle('Pair Plot of Key Metrics Across States', y=1.02, fontsize=16)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize relationships between all pairs of numeric variables.\n",
        "\n",
        "Spot positive/negative trends, linear associations, or potential clusters.\n",
        "\n",
        "Understand how variables are distributed and whether any anomalies/outliers exist."
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A clear positive linear trend between:\n",
        "\n",
        "Registered_Users and App_Opens\n",
        "\n",
        "Transaction_Count and Transaction_Amount\n",
        "\n",
        "Variables like Insurance_Count and Insurance_Amount show weaker but visible patterns.\n",
        "\n",
        "Outliers or skewed distributions (visible via diagonal KDE plots) indicate further preprocessing or transformation might be needed."
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 🔹 **Hypothesis 1:**\n",
        "\n",
        "> ❓ **Does the average transaction amount significantly differ between high-user states (top 10) and low-user states (bottom 10)?**\n",
        "\n",
        "* **Null Hypothesis (H₀):**\n",
        "  The average transaction amount is the same in high-user and low-user states.\n",
        "\n",
        "* **Alternate Hypothesis (H₁):**\n",
        "  The average transaction amount is significantly different between the two groups.\n",
        "\n",
        "---\n",
        "\n",
        "### 🔹 **Hypothesis 2:**\n",
        "\n",
        "> ❓ **Do states with higher registered users have higher insurance adoption rates (in terms of premium amount)?**\n",
        "\n",
        "* **Null Hypothesis (H₀):**\n",
        "  There is no correlation between registered users and insurance premium amount.\n",
        "\n",
        "* **Alternate Hypothesis (H₁):**\n",
        "  There is a significant positive correlation between registered users and insurance premium amount.\n",
        "\n",
        "---\n",
        "\n",
        "### 🔹 **Hypothesis 3:**\n",
        "\n",
        "> ❓ **Does the number of app opens significantly vary by quarter (Q1–Q4)?**\n",
        "\n",
        "* **Null Hypothesis (H₀):**\n",
        "  Mean app opens are equal across all quarters.\n",
        "\n",
        "* **Alternate Hypothesis (H₁):**\n",
        "  Mean app opens vary significantly across quarters.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null & Alternate Hypothesis\n",
        "Null Hypothesis (H₀):\n",
        "The average transaction amount is the same in high-user states and low-user states.\n",
        "\n",
        "Alternate Hypothesis (H₁):\n",
        "The average transaction amount is significantly different in high-user states compared to low-user states.\n",
        "\n"
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "# Get total registered users per state\n",
        "users_per_state = df_map_user.groupby('State')['RegisteredUsers'].sum()\n",
        "\n",
        "# Get transaction amount per state\n",
        "txn_per_state = df_agg_trans.groupby('State')['TransactionAmount'].sum()\n",
        "\n",
        "# Merge into one DataFrame\n",
        "merged_df = pd.DataFrame({\n",
        "    'RegisteredUsers': users_per_state,\n",
        "    'TransactionAmount': txn_per_state\n",
        "}).dropna()\n",
        "\n",
        "# Sort by users to define high-user and low-user groups\n",
        "sorted_states = merged_df.sort_values('RegisteredUsers', ascending=False)\n",
        "\n",
        "high_users = sorted_states.head(10)['TransactionAmount']\n",
        "low_users = sorted_states.tail(10)['TransactionAmount']\n",
        "\n",
        "# Perform independent t-test\n",
        "t_stat, p_val = ttest_ind(high_users, low_users, equal_var=False)\n",
        "print(f\"T-statistic: {t_stat:.4f}\")\n",
        "print(f\"P-value: {p_val:.4f}\")\n"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Independent two-sample t-test\n",
        "\n"
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We’re comparing the mean of two independent groups (top 10 and bottom 10 states by user base) on a continuous variable (TransactionAmount).\n",
        "Since we're testing for mean differences, the t-test is appropriate here."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Null & Alternate Hypothesis\n",
        "Null Hypothesis (H₀):\n",
        "There is no correlation between registered users and insurance premium amount.\n",
        "\n",
        "Alternate Hypothesis (H₁):\n",
        "There is a significant positive correlation between registered users and insurance premium amount."
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "# Group and align data\n",
        "insurance_amt = df_agg_insurance.groupby('State')['Insurance_Amount'].sum()\n",
        "users = df_map_user.groupby('State')['RegisteredUsers'].sum()\n",
        "\n",
        "# Merge\n",
        "df_corr = pd.DataFrame({\n",
        "    'RegisteredUsers': users,\n",
        "    'InsuranceAmount': insurance_amt\n",
        "}).dropna()\n",
        "\n",
        "# Pearson correlation test\n",
        "corr, p_val = pearsonr(df_corr['RegisteredUsers'], df_corr['InsuranceAmount'])\n",
        "print(f\"Correlation Coefficient: {corr:.4f}\")\n",
        "print(f\"P-value: {p_val:.4f}\")\n"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pearson Correlation Test"
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're measuring the linear relationship between two continuous variables: RegisteredUsers and Insurance_Amount.\n",
        "Pearson’s test is ideal for correlation strength and significance."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Null & Alternate Hypothesis\n",
        "Null Hypothesis (H₀):\n",
        "Mean app opens are equal across all quarters (Q1 to Q4).\n",
        "\n",
        "Alternate Hypothesis (H₁):\n",
        "Mean app opens significantly differ across quarters."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "from scipy.stats import f_oneway\n",
        "\n",
        "# Group by quarter and collect app opens\n",
        "q1 = df_map_user[df_map_user['Quarter'] == 1]['AppOpens']\n",
        "q2 = df_map_user[df_map_user['Quarter'] == 2]['AppOpens']\n",
        "q3 = df_map_user[df_map_user['Quarter'] == 3]['AppOpens']\n",
        "q4 = df_map_user[df_map_user['Quarter'] == 4]['AppOpens']\n",
        "\n",
        "# Perform one-way ANOVA\n",
        "f_stat, p_val = f_oneway(q1, q2, q3, q4)\n",
        "print(f\"F-statistic: {f_stat:.4f}\")\n",
        "print(f\"P-value: {p_val:.4f}\")\n"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One-Way ANOVA"
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're comparing the means across more than two groups (quarters). ANOVA helps test if at least one quarter differs significantly in app opens."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "# Check missing values\n",
        "df_agg_trans.isnull().sum()\n",
        "\n",
        "# Drop rows with missing data if very few\n",
        "df_agg_trans = df_agg_trans.dropna()\n",
        "\n",
        "# OR: Impute missing values in count-based column\n",
        "df_map_user['AppOpens'].fillna(df_map_user['AppOpens'].median(), inplace=True)\n",
        "\n",
        "# Example: Mean imputation for Insurance Amount\n",
        "df_agg_insurance['Insurance_Amount'].fillna(df_agg_insurance['Insurance_Amount'].mean(), inplace=True)\n"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "We performed **missing value analysis** on each table (`aggregated_transaction`, `map_user`, `map_insurance`, etc.) and identified the missing/null entries (if any).\n",
        "\n",
        "---\n",
        "\n",
        "### 📌 **Imputation Techniques Used & Why**\n",
        "\n",
        "| Technique                  | Description                                                   | Where Used                                                                      | Why Used                                                                                            |\n",
        "| -------------------------- | ------------------------------------------------------------- | ------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------- |\n",
        "| **Drop Missing Rows**      | Completely removed rows with missing values.                  | Used in most tables like `aggregated_transaction`, `map_user` if rows were few. | Safe when the number of missing rows is **insignificant** compared to total. Avoids injecting bias. |\n",
        "| **Mean/Median Imputation** | Replaced missing numerical values with column mean or median. | Example: `AppOpens` or other metrics where zero would be misleading.            | Maintains central tendency, avoids dropping useful rows.                                            |\n",
        "| **Forward Fill (ffill)**   | Propagates last valid value forward.                          | Can be used in time-series-like data (if present).                              | Useful when values don’t change abruptly (not used here unless date-wise trends exist).             |\n",
        "| **Zero Imputation**        | Replaced missing values with zero.                            | Only for **count-based** features like `TransactionCount` or `AppOpens`.        | Logical when missing means \"no activity\". Avoid for monetary fields.                                |\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Example: Outlier detection for Transaction_Amount\n",
        "sns.boxplot(data=df_agg_trans, x='TransactionAmount')\n",
        "plt.title(\"Outlier Detection - Transaction_Amount\")\n",
        "plt.show()\n",
        "\n",
        "# Calculate IQR for outlier removal\n",
        "Q1 = df_agg_trans['TransactionAmount'].quantile(0.25)\n",
        "Q3 = df_agg_trans['TransactionAmount'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "# Remove outliers\n",
        "df_agg_trans = df_agg_trans[\n",
        "    (df_agg_trans['TransactionAmount'] >= Q1 - 1.5 * IQR) &\n",
        "    (df_agg_trans['TransactionAmount'] <= Q3 + 1.5 * IQR)\n",
        "]\n"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For insurance amount\n",
        "Q1 = df_agg_insurance['Insurance_Amount'].quantile(0.25)\n",
        "Q3 = df_agg_insurance['Insurance_Amount'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "df_agg_insurance = df_agg_insurance[\n",
        "    (df_agg_insurance['Insurance_Amount'] >= Q1 - 1.5 * IQR) &\n",
        "    (df_agg_insurance['Insurance_Amount'] <= Q3 + 1.5 * IQR)\n",
        "]\n"
      ],
      "metadata": {
        "id": "JhJGrYmnQQaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Technique                           | Description                                          | Where Used                                                      | Why Used                                                                                           |\n",
        "| ----------------------------------- | ---------------------------------------------------- | --------------------------------------------------------------- | -------------------------------------------------------------------------------------------------- |\n",
        "| **IQR Method**                      | Removes values outside 1.5×IQR range                 | Applied to `Transaction_Amount`, `Insurance_Amount`, `AppOpens` | IQR is robust for detecting outliers in skewed data and avoids removing genuine but extreme values |\n",
        "| **Boxplot Visualization**           | Identified visual outliers before removing           | All numeric features                                            | Helps in detecting outliers visually for domain-specific judgment                                  |\n",
        "| **Log Transformation** *(Optional)* | Applied if skewness is high (not necessary here yet) | Optional                                                        | Reduces impact of high-value outliers in visualization (but not for dashboard KPIs)                |\n"
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Textual Data Preprocessing\n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Expand Contraction"
      ],
      "metadata": {
        "id": "GMQiZwjn3iu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Expand Contraction"
      ],
      "metadata": {
        "id": "PTouz10C3oNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Lower Casing"
      ],
      "metadata": {
        "id": "WVIkgGqN3qsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lower Casing"
      ],
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Removing Punctuations"
      ],
      "metadata": {
        "id": "XkPnILGE3zoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Punctuations"
      ],
      "metadata": {
        "id": "vqbBqNaA33c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Removing URLs & Removing words and digits contain digits."
      ],
      "metadata": {
        "id": "Hlsf0x5436Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove URLs & Remove words and digits contain digits"
      ],
      "metadata": {
        "id": "2sxKgKxu4Ip3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Removing Stopwords & Removing White spaces"
      ],
      "metadata": {
        "id": "mT9DMSJo4nBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Stopwords"
      ],
      "metadata": {
        "id": "T2LSJh154s8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove White spaces"
      ],
      "metadata": {
        "id": "EgLJGffy4vm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. Rephrase Text"
      ],
      "metadata": {
        "id": "c49ITxTc407N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rephrase Text"
      ],
      "metadata": {
        "id": "foqY80Qu48N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7. Tokenization"
      ],
      "metadata": {
        "id": "OeJFEK0N496M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization"
      ],
      "metadata": {
        "id": "ijx1rUOS5CUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8. Text Normalization"
      ],
      "metadata": {
        "id": "9ExmJH0g5HBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing Text (i.e., Stemming, Lemmatization etc.)"
      ],
      "metadata": {
        "id": "AIJ1a-Zc5PY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text normalization technique have you used and why?"
      ],
      "metadata": {
        "id": "cJNqERVU536h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Z9jKVxE06BC1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9. Part of speech tagging"
      ],
      "metadata": {
        "id": "k5UmGsbsOxih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# POS Taging"
      ],
      "metadata": {
        "id": "btT3ZJBAO6Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 10. Text Vectorization"
      ],
      "metadata": {
        "id": "T0VqWOYE6DLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizing Text"
      ],
      "metadata": {
        "id": "yBRtdhth6JDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text vectorization technique have you used and why?"
      ],
      "metadata": {
        "id": "qBMux9mC6MCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "su2EnbCh6UKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Correlation matrix for aggregated transaction\n",
        "corr_matrix = df_agg_trans[['TransactionAmount', 'TransactionCount']].corr()\n",
        "\n",
        "# Plot heatmap\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
        "plt.title(\"Correlation Matrix - Aggregated Transaction\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Average Transaction Value per Count\n",
        "df_agg_trans['Avg_Txn_Value'] = df_agg_trans['TransactionAmount'] / df_agg_trans['TransactionCount']\n",
        "df_agg_trans['Avg_Txn_Value'].replace([float('inf'), -float('inf')], 0, inplace=True)\n",
        "\n",
        "# 2. Quarterly Growth Rate of Transactions (assuming year-quarter sorting)\n",
        "df_agg_trans = df_agg_trans.sort_values(['State', 'Year', 'Quarter'])\n",
        "df_agg_trans['Txn_Growth'] = df_agg_trans.groupby('State')['TransactionAmount'].pct_change().fillna(0)\n",
        "\n",
        "# 3. App Opens per User (in map_user table)\n",
        "df_map_user['AppOpens_per_User'] = df_map_user['AppOpens'] / df_map_user['RegisteredUsers']\n",
        "df_map_user['AppOpens_per_User'].replace([float('inf'), -float('inf')], 0, inplace=True)\n",
        "\n",
        "# 4. Insurance Premium per Policy\n",
        "df_agg_insurance['Premium_per_Policy'] = df_agg_insurance['Insurance_Amount'] / df_agg_insurance['Insurance_Count']\n",
        "df_agg_insurance['Premium_per_Policy'].replace([float('inf'), -float('inf')], 0, inplace=True)\n"
      ],
      "metadata": {
        "id": "yzYf9VB6QzZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select your features wisely to avoid overfitting\n",
        "# Check feature correlation\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Selecting numeric columns only\n",
        "numeric_cols = df_agg_trans.select_dtypes(include=['float64', 'int64']).columns\n",
        "\n",
        "# Correlation matrix\n",
        "corr_matrix = df_agg_trans[numeric_cols].corr()\n",
        "\n",
        "# Heatmap to visualize multicollinearity\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
        "plt.title(\"Feature Correlation Heatmap\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Method                      | Description                                                 | Why Used                                                           |\n",
        "| --------------------------- | ----------------------------------------------------------- | ------------------------------------------------------------------ |\n",
        "| **Correlation Matrix**      | Checked for multicollinearity among numeric features        | Avoids using two highly similar features that convey the same info |\n",
        "| **Domain Knowledge**        | Chose features based on their real-world business relevance | Ensures the dashboard and visuals reflect user behavior & value    |\n",
        "| **Manual Feature Dropping** | Removed features like IDs or unnamed values                 | They're irrelevant for insights                                    |\n"
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Feature                  | Reason                                                   |\n",
        "| ------------------------ | -------------------------------------------------------- |\n",
        "| **Transaction\\_Amount**  | Represents monetary flow; key to financial health        |\n",
        "| **Transaction\\_Count**   | Reflects engagement and usage frequency                  |\n",
        "| **Avg\\_Txn\\_Value**      | Ticket size of typical user payment – impacts marketing  |\n",
        "| **AppOpens\\_per\\_User**  | Indicates user engagement with the app                   |\n",
        "| **Premium\\_per\\_Policy** | Reflects trust in PhonePe’s insurance services           |\n",
        "| **State, Year, Quarter** | Crucial for temporal and geographic insights             |\n",
        "| **Txn\\_Growth**          | Helps identify states with fast-growing digital adoption |\n"
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DImensionality Reduction (If needed)"
      ],
      "metadata": {
        "id": "kQfvxBBHDvCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ],
      "metadata": {
        "id": "T5CmagL3EC8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "ZKr75IDuEM7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely."
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "VFOzZv6IFROw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "GeKDIv7pFgcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Imbalanced Dataset (If needed)"
      ],
      "metadata": {
        "id": "nQsRhhZLFiDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ],
      "metadata": {
        "id": "TIqpNgepFxVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "qbet1HwdGDTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DashBoard Creation**\n",
        "\n"
      ],
      "metadata": {
        "id": "e7w9XCYHTQKg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conn.commit()\n",
        "conn.close()"
      ],
      "metadata": {
        "id": "UkmnL2_aiSp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit tensorflow\n"
      ],
      "metadata": {
        "id": "_7UVazecoYe1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok\n"
      ],
      "metadata": {
        "id": "QDmr4DPsodTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()  # upload main.py\n"
      ],
      "metadata": {
        "id": "fPUDoTNAo2Wy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "os.system(\"streamlit run /content/main.py &\")"
      ],
      "metadata": {
        "id": "Lql-CN63oiiD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conn = sqlite3.connect('phonepe.db')  # Use your actual file path here\n"
      ],
      "metadata": {
        "id": "BvfNhtcVlSTN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.read_sql(\"PRAGMA table_info(aggregated_user);\", conn)\n"
      ],
      "metadata": {
        "id": "ITvvRqvqkrDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.read_sql(\"PRAGMA table_info(top_map);\", conn)\n"
      ],
      "metadata": {
        "id": "LPHjCVJZn1mW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl ipv4.icanhazip.com\n"
      ],
      "metadata": {
        "id": "a35Tv_yDooah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run  /content/main.py & npx localtunnel --port 8501\n"
      ],
      "metadata": {
        "id": "wy0vTROxosME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "The **PhonePe Transaction Insights** project successfully demonstrates the power of data analysis and visualization in understanding user behavior, transaction patterns, and financial service adoption across India. By leveraging structured datasets from the PhonePe Pulse repository and employing **SQL for querying**, **Pandas for processing**, and **Streamlit for dashboarding**, we gained actionable insights across multiple dimensions:\n",
        "\n",
        "* **Top performing states and districts** were identified based on transaction volume and value, helping understand geographical hotspots for digital payment activity.\n",
        "* **User growth trends** were visualized quarter-wise, providing a clear picture of how digital payment adoption has accelerated over time.\n",
        "* **Insurance adoption patterns** were analyzed to explore financial inclusivity across regions.\n",
        "* Multiple hypotheses were tested to validate assumptions about digital payment behaviors using statistical methods.\n",
        "\n",
        "Key business use cases such as **customer segmentation**, **marketing optimization**, **product development**, and **fraud detection** were addressed through visual storytelling and data-driven insights. The developed **interactive dashboard** enables real-time exploration of transaction data, empowering stakeholders to make informed decisions.\n",
        "\n",
        "This project not only improved technical skills in **SQL, Python, EDA, data visualization, and dashboarding**, but also emphasized the importance of **clean data, meaningful features, and domain understanding** in driving impactful analysis. The final solution is robust, scalable, and can be extended for future use cases such as forecasting and credit risk analysis.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}